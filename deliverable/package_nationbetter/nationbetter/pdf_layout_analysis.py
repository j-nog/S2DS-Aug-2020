#!/usr/bin/env python
# coding: utf-8


import pandas as pd
import numpy as np
import difflib
from .file_handler import get_inner_folder, import_source_to_df, write_files

def pdf_dict_to_outputformat(in_file,out_path):
    """
    Takes a dict passed by scraped_pdf_by_line() with columns [pages numbers, box
    numbers, box positions, line numbers, currentline fontsize (non-spacelike),
    text of line] and sections the text into a dataframe containing separate text
    boxes for main_text, titles, subtitles etc. and numbers them correctly
    """
    write_path  = get_inner_folder(out_path,'formatted_pdf_dfs')
    print('Extracting contents of {}, to DataFrame'.format(in_file))
    df = import_source_to_df(in_file)

    #finding main text fontsize by counting most used text font for each line
    fontcount = df['line_no'].groupby(df['curr_linefontsize'].round(decimals = 0)).count()
    textsize = fontcount.idxmax()

    #Creating indexes for labeling fontsizes in the documents as text_type.
    #Labels for fontsizes are automaticaly generated by comparing the size of the text
    #(... < subsubtext < subtext < text < subsub..title < ...< title)
    fontsizes = df['curr_linefontsize'].groupby(df['curr_linefontsize'].round(decimals = 0)).unique().keys()
    fontkeys = ['main_text']
    supindex = fontsizes > textsize
    subindex = fontsizes < textsize
    for count in range(sum(supindex)):
        fontkeys.append((sum(supindex)-count-1)*'sub'+'title')
    for count in range(sum(subindex)):
        fontkeys.insert(0,(count+1)*'sub'+'text')
    fontsizes = fontsizes.append(pd.Index([np.nan]))
    fontkeys.append(np.nan)

    #Creating extra column containing text_type
    def compare_font(entry):
        fontsize_entry = fontsizes.get_loc(round(entry,0))
        return(fontkeys[fontsize_entry])
    df['text_type'] = df['curr_linefontsize'].apply(compare_font)

    #Creating extra columns to fix cutting of sentences due to PDFminers selection
    #of horizontal textboxes (see documentation)
    df[['x0_ln','y0_ln','x1_ln','y1_ln']] = pd.DataFrame(df['line_pos'].tolist())
    df.sort_values(by=['page_no','y0_ln','x0_ln'],ascending = [True,False,True],ignore_index=True,inplace=True)


    no_breaks = df[df['text_type'].notnull()].round({'y0_ln':1,'x0_ln':1,'y1_ln':1,'x1_ln':1})

    # Kills bottom line by sorting and aligning by bottom left coordinate of
    # sentence box. If lines are very similar (overlap) measured by tolerance
    # drop the lines.

    def check_empty_iterator(iterator):
        try:
            next(iterator)
        except StopIteration:
            pass

    def kill_footers(tolerance = 0.9):
        bottom_ln = no_breaks.round({'y0_ln':1})['y0_ln'].min()
        to_match = no_breaks[no_breaks.y0_ln==bottom_ln].sort_values(by='x0_ln')['text']
        it1 = to_match.iteritems()
        it2 = to_match.iteritems()
        overlap = []
        check_empty_iterator(it2)
        for step in range(len(to_match)-1):
            value = next(it1)
            next_value = next(it2)
            match = difflib.SequenceMatcher(None,value[1],next_value[1])
            overlap.append(match.ratio())
        if overlap:
            if(sum(overlap)/len(overlap)) > tolerance:
                df.drop(to_match.index,inplace = True)
                print('footer deleted, if trailing characters occur rerun \
                        example_build_data.kill_footers')
        else:
            print('no footer with tolerance level {}'.format(tolerance))

    def kill_headers(tolerance = 0.9):
        top_ln = no_breaks.round({'y1_ln':1})['y1_ln'].max()
        to_match = no_breaks[no_breaks.y1_ln==top_ln].sort_values(by='x1_ln')['text']
        it1 = to_match.iteritems()
        it2 = to_match.iteritems()
        overlap = []
        check_empty_iterator(it2)
        for step in range(len(to_match)-1):
            value = next(it1)
            next_value = next(it2)
            match = difflib.SequenceMatcher(None,value[1],next_value[1])
            overlap.append(match.ratio())
        if overlap:
            if(sum(overlap)/len(overlap)) > tolerance:
                df.drop(to_match.index,inplace = True)
                print('Header deleted, if trailing characters occur rerun \
                        example_build_data.kill_headers')
        else:
            print('no header with tolerance level {}'.format(tolerance))
    kill_footers()
    kill_headers()

    #Add collumn tracking if type of text_type changes
    def riffle_repeated_type():
        notnull_df = df[df['text_type'].notnull()]
        return (notnull_df[['text_type']] == notnull_df[['text_type']].shift()).any(axis=1)
    df['text_type'] = df['text_type'].fillna(method= 'bfill').fillna(method = 'ffill')
    text_type_change = ~riffle_repeated_type().reindex(df.index).fillna(True)
    text_type_change[0] = False
    df['type_change'] = text_type_change

    def create_section_index():
        """
        Create new columns automaticaly for indexing (integer) levels of sub(secitons)
        in text.
        """
        notnull_df = df[df['text_type'].notnull()]
        #create sorted column names containing text_type unequal to main_text
        u_index = df.sort_values(by = 'curr_linefontsize')\
                 .groupby(notnull_df['curr_linefontsize'].round(decimals = 0))\
                 ['text_type'].unique().drop(textsize)
        u_index = np.array([u_index.iloc[ntry][0] for ntry in range(u_index.size)])
        sec_counters = []
        [sec_counters.append(0) for section_level in range(len(u_index))]
        counter_df = pd.DataFrame([sec_counters],columns = u_index)
        # appending to df
        df[u_index] = counter_df #pd.concat([df,counter_df],axis=1)
        df[u_index] = df[u_index].ffill(0)
        return u_index

    def iter_the_cols(df_in,list_ind):
        """
        Adds 1 to the column generatied by df.create_secton_index()
        (say subsection) if a change of text type occurs (say from
        susection to main_text). Total section index obtained by cumsum
        over these columns
        """
        if df_in['type_change'] == True:
            if df_in['text_type'] in df_in.keys():
                level = np.where(list_ind==df_in['text_type'])[0]
                df_in[df_in['text_type']] =1
                for entry in range(level[0]):
                    df_in[list_ind[entry]]=0
                #df_in[list_ind]=df_in[list_ind].ffill()
        return df_in
    #finishing up numbering of sections
    u_index = create_section_index()
    df = df.apply(iter_the_cols,list_ind=u_index,axis=1)
    df[u_index[-1]]=df[u_index[-1]].cumsum()
    for depth in range(len(u_index)-1):
        df[u_index[-2-depth]]=df.groupby(u_index[-1-depth])[u_index[-2-depth]].cumsum()

    #creating output format
    groups = list(u_index)[::-1]
    groups.append('text_type')
    out_keys = groups.copy()
    out_keys.insert(0,'page_no')
    out_keys.append('text')
    out_keys.append('url')
    df_out = df[out_keys]
    df_out2 = df_out.groupby(groups,sort=False).agg({'page_no':'first','text':'sum','url':'first'}).reset_index() 
    write_files(df_out2,write_path,in_file,'pickle')
