{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo notebook for flashtext package\n",
    "\n",
    "https://github.com/vi3k6i5/flashtext  \n",
    "\n",
    "28x faster than a compiled regexp for 1k keywords & ~10k tokens per document https://twitter.com/RadimRehurek/status/904989624589803520\n",
    "\n",
    "Pure Python too, so prolly lots of room to opt.\n",
    "Some of the functionality (fuzzy match implementation) does not exist while using \n",
    "\n",
    "**pip install flashtext**\n",
    "\n",
    "https://github.com/vi3k6i5/flashtext/blob/master/flashtext/keyword.py (Line 756) \n",
    "\n",
    "So, instead, to retrive the newest one from Github, that can be done  \n",
    "\n",
    "**pip install git+https://github.com/vi3k6i5/flashtext.git#egg=flashtext**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single corpus usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This guidance is for organisations who want to apply for a sponsor licence to \\nsponsor migrants under Tier 2 and/or Tier 5 of the points-based system. It \\ntells you what we expect if you are a licence holder, the processes you must \\nfollow when sponsoring a migrant and how to meet all of the duties and \\nresponsibilities associated with being a licensed sponsor. The guidance is \\nsubject to change and you should check the dates to make sure you have \\nthe latest version. \\n \\nA new points-based immigration system will come into effect from 1 January \\n2021. The future system will apply to both European Economic Area (EEA) \\nnationals and non-EEA nationals. You should refer to Annex 9 of this \\nguidance if you intend to apply for a licence to sponsor workers under the \\nnew system.  \\n \\nSeparate guidance exists on GOV.UK for UK education providers who wish \\nto apply for and hold a licence to sponsor international students to come to \\nthe UK under Tier 4 to study. \\n \\nYou can find the appendices mentioned in this guidance under sponsorship policy \\nguidance on the â€˜Guidance for employers and educators' page on GOV.UK. \\n \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data contains raw text for each sections within a document\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"input/2020-07-16_Tier-2-5-sponsor-guidance_Jul-2020_v1.0_section.csv\", index_col=0)\n",
    "document = df.raw_text.iloc[1]\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tier 2', 102, 108), ('Tier 5', 116, 122), ('EEA', 595, 617), ('non-EEA', 625, 634), ('non-EEA', 647, 656), ('Annex 9', 678, 685), ('Tier 4', 950, 956)]\n"
     ]
    }
   ],
   "source": [
    "keyword_processor = KeywordProcessor(case_sensitive=True) # default is True\n",
    "\n",
    "# keyword_processor.add_keyword(<unclean name>, <standardised name>)\n",
    "#keyword_processor.add_keyword('Tier 2 and/or Tier 5')\n",
    "keyword_processor.add_keyword('Tier 2')\n",
    "keyword_processor.add_keyword('Tier 5')\n",
    "keyword_processor.add_keyword('European Economic Area', 'EEA')\n",
    "keyword_processor.add_keyword('nationals', 'non-EEA')\n",
    "keyword_processor.add_keyword('Annex 9')\n",
    "keyword_processor.add_keyword('Tier 4', 'Tier 4')\n",
    "\n",
    "\"\"\"\n",
    "It returns the keywords found in the document (corpus) and their relevant positions\n",
    "\"\"\"\n",
    "keywords_found = keyword_processor.extract_keywords(document, span_info=True)\n",
    "print(keywords_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Immigration status', 'Tier 2'), 102, 108),\n",
       " (('Immigration status', 'Tier 5'), 116, 122),\n",
       " (('Location', 'non-EEA'), 639, 646)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "add_keyword method takes 2 argumens (keyword, clean_name)\n",
    "\n",
    "keyword : (string)     Keyword that you want to identify\n",
    "clean_name : (string)  Clean term for that keyword that you would want to get back in return or replace\n",
    "                       if not provided, keyword will be used as the clean name also.\n",
    "\"\"\"\n",
    "keyword_processor = KeywordProcessor()\n",
    "keyword_processor.add_keyword('Tier 2', ('Immigration status', 'Tier 2'))\n",
    "keyword_processor.add_keyword('Tier 5', ('Immigration status', 'Tier 5'))\n",
    "keyword_processor.add_keyword('non-EEA', ('Location', 'non-EEA'))\n",
    "keywords_extracted = keyword_processor.extract_keywords(document, span_info=True)\n",
    "keywords_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "['immigration_status', 'immigration_status', 'UK_regions', 'immigration_status']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "add_keywords_from_dict   Method returns the key of the given keywords values\n",
    "add_keywords_from_list   Similar to dict method\n",
    "\"\"\"\n",
    "keyword_processor = KeywordProcessor()\n",
    "\n",
    "keyword_dict = {\n",
    "    \"immigration_status\" : [\"Tier\", \"Start-up\", \"Innovator\", \"Global Talent\"],\n",
    "    \"UK_regions\" : [\"non-EEA\", \"England\", \"Wales\", \"Scotland\", \"Northern Ireland\"]\n",
    "}\n",
    "\n",
    "keyword_processor.add_keywords_from_dict(keyword_dict)\n",
    "print(len(keyword_processor))\n",
    "print(keyword_processor.extract_keywords(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single file usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data contains raw texts for each page\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"input/2020-07-16_Tier-2-5-sponsor-guidance_Jul-2020_v1.0_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copied the list of keywords created by @Bernhard and @Joao\n",
    "https://docs.google.com/spreadsheets/d/1ViWKwayEa-k5mdp2T9swBnQLq0L_21uITWRRK46AWCQ/edit#gid=0\n",
    "\n",
    "Maybe used the one @Larisa shared\n",
    "https://docs.google.com/spreadsheets/d/1E4RWT0MUCzU5UpVuVGGcjUOqYyIfMuhD8oyodtDcu_w/edit#gid=0\n",
    "\"\"\"\n",
    "keyword_processor = KeywordProcessor()\n",
    "keyword_processor.add_keyword_from_file('input/Tier-2-5-sponsor-guidance_Jul-2020_v1.0_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++ Page number : 1 +++++++++++++++++++++++++\n",
      "\n",
      "['tier', 'guidance', 'tier', 'guidance', 'tier', 'sponsor', 'licence', 'sponsor', 'tier', 'tier', 'licence', 'sponsor', 'guidance', 'sponsorship', 'Home Office', 'Home Office', 'sponsor', 'licence', 'sponsor']\n",
      "\n",
      "{'sponsorship', 'guidance', 'tier', 'sponsor', 'licence', 'Home Office'}\n",
      "\n",
      "+++++++++++++ Page number : 2 +++++++++++++++++++++++++\n",
      "\n",
      "['guidance', 'guidance', 'tier', 'tier', 'sponsor', 'licence', 'certificates of sponsorship', 'guidance']\n",
      "\n",
      "{'guidance', 'certificates of sponsorship', 'tier', 'sponsor', 'licence'}\n",
      "\n",
      "+++++++++++++ Page number : 3 +++++++++++++++++++++++++\n",
      "\n",
      "['tier', 'guidance', 'guidance', 'guidance', 'sponsor', 'guidance', 'licence', 'sponsorship', 'tier', 'tier', 'sponsorship', 'licence', 'licence', 'tier', 'tier', 'tier', 'tier', 'tier', 'tier', 'tier', 'tier', 'tier', 'tier', 'Government Authorised Exchange', 'tier', 'guidance']\n",
      "\n",
      "{'sponsorship', 'guidance', 'tier', 'sponsor', 'licence', 'Government Authorised Exchange'}\n",
      "\n",
      "+++++++++++++ Page number : 4 +++++++++++++++++++++++++\n",
      "\n",
      "['tier', 'sponsor', 'licence', 'key personnel', 'key personnel', 'authorising officer', 'key contact', 'level 1 user', 'level 2 user', 'suitability criteria', 'sponsor', 'licence', 'sponsor', 'licence', 'sponsorship management system', 'sponsorship management system', 'company voluntary arrangement', 'guidance']\n",
      "\n",
      "{'key personnel', 'guidance', 'tier', 'authorising officer', 'company voluntary arrangement', 'key contact', 'sponsorship management system', 'sponsor', 'level 2 user', 'licence', 'suitability criteria', 'level 1 user'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Looping over each page and extract the given keywords\n",
    "\"\"\"\n",
    "for i in range(len(df)):\n",
    "    page_document = df.raw_text.iloc[i]\n",
    "    print(\"\\n+++++++++++++ Page number : %d +++++++++++++++++++++++++\\n\" % (i+1))\n",
    "    keywords_extracted = keyword_processor.extract_keywords(page_document)\n",
    "    print(keywords_extracted)\n",
    "    print()\n",
    "    print(set(keywords_extracted))\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other uses\n",
    "\n",
    "This part was not clear to me, but it finds the fuzzy keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_keyword_': 'Mary'}, 1, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrieve the nodes where there is a fuzzy match,\n",
    "via levenshtein distance, and with respect to max_cost\n",
    "Args:\n",
    "    word (str): word to find a fuzzy match for\n",
    "    max_cost (int): maximum levenshtein distance when performing the fuzzy match\n",
    "    start_node (dict): Trie node from which the search is performed\n",
    "Yields:\n",
    "    node, cost, depth (tuple): A tuple containing the final node,\n",
    "                              the cost (i.e the distance), and the depth in the trie\n",
    "\"\"\"\n",
    "keyword_processor = KeywordProcessor(case_sensitive=True)\n",
    "keyword_processor.add_keyword('Marie', 'Mary')\n",
    "next(keyword_processor.levensthein('Maria', max_cost=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({' ': {'B': {'l': {'a': {'n': {'c': {'_keyword_': 'Mary'}}}}}}}, 1, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_processor = KeywordProcessor(case_sensitive=True)\n",
    "keyword_processor.add_keyword('Marie Blanc', 'Mary')\n",
    "next(keyword_processor.levensthein('Mari', max_cost=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('keyword with many words', 25, 48)]\n",
      "[('keyword', 25, 31)]\n"
     ]
    }
   ],
   "source": [
    "keyword_proc = KeywordProcessor()\n",
    "keyword_proc.add_keyword('keyword')\n",
    "keyword_proc.add_keyword('keyword with many words')\n",
    "sentence = \"This sentence contains a keywrd with many woords\"\n",
    "print(keyword_proc.extract_keywords(sentence, span_info=True, max_cost=2))\n",
    "print(keyword_proc.extract_keywords(sentence, span_info=True, max_cost=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
